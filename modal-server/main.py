"""
LTX-Video Service for AI Video Generation
ì”¬ë‹¹ 8ì´ˆ ì§œë¦¬ AI ì˜ìƒì„ ë¹ ë¥´ê³  ì €ë ´í•˜ê²Œ ìƒì„±í•˜ëŠ” Modal ì„œë¹„ìŠ¤
"""

import modal
from pathlib import Path

# ============================================================================
# 1. ì´ë¯¸ì§€ ì„¤ì •: í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜
# ============================================================================
image = modal.Image.debian_slim().pip_install(
    "torch",
    "diffusers",
    "transformers",
    "accelerate",
    "sentencepiece",
    "huggingface_hub",
    "pillow",  # ì´ë¯¸ì§€ ì²˜ë¦¬ìš©
    "requests"  # ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œìš©
)

# ============================================================================
# 2. ë³¼ë¥¨ ì„¤ì •: ëª¨ë¸ ìºì‹œ (ë§¤ë²ˆ ë‹¤ìš´ë¡œë“œ ë°©ì§€)
# ============================================================================
model_cache = modal.Volume.from_name(
    "model-cache",
    create_if_missing=True
)

MODEL_DIR = "/models"
MODEL_NAME = "Lightricks/LTX-Video"

# ============================================================================
# 3. Modal ì•± ì •ì˜
# ============================================================================
app = modal.App("ltx-video-service")

# ============================================================================
# 4. ëª¨ë¸ ë‹¤ìš´ë¡œë“œ í•¨ìˆ˜ (ìµœì´ˆ 1íšŒë§Œ ì‹¤í–‰)
# ============================================================================
@app.function(
    image=image,
    volumes={MODEL_DIR: model_cache},
    secrets=[modal.Secret.from_name("huggingface-secret")],
    timeout=3600,  # 1ì‹œê°„ (ëª¨ë¸ ë‹¤ìš´ë¡œë“œëŠ” ì‹œê°„ì´ ê±¸ë¦´ ìˆ˜ ìˆìŒ)
)
def download_model():
    """
    Hugging Faceì—ì„œ LTX-Video ëª¨ë¸ì„ ë‹¤ìš´ë¡œë“œí•©ë‹ˆë‹¤.
    ëª¨ë¸ì´ ì´ë¯¸ ìˆìœ¼ë©´ ìŠ¤í‚µí•©ë‹ˆë‹¤.
    """
    from huggingface_hub import snapshot_download
    import os

    model_path = Path(MODEL_DIR) / MODEL_NAME.replace("/", "--")

    # ëª¨ë¸ì´ ì´ë¯¸ ìˆëŠ”ì§€ í™•ì¸
    if model_path.exists() and any(model_path.iterdir()):
        print(f"âœ… ëª¨ë¸ì´ ì´ë¯¸ ì¡´ì¬í•©ë‹ˆë‹¤: {model_path}")
        return str(model_path)

    print(f"ğŸ“¥ ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ì¤‘: {MODEL_NAME}")
    print(f"ğŸ“ ì €ì¥ ìœ„ì¹˜: {model_path}")

    # Hugging Faceì—ì„œ ëª¨ë¸ ë‹¤ìš´ë¡œë“œ
    hf_token = os.environ.get("HF_TOKEN")

    downloaded_path = snapshot_download(
        repo_id=MODEL_NAME,
        local_dir=str(model_path),
        token=hf_token,
        ignore_patterns=["*.md", "*.txt"]  # ë¶ˆí•„ìš”í•œ íŒŒì¼ ì œì™¸
    )

    # ë³¼ë¥¨ì— ë³€ê²½ì‚¬í•­ ì €ì¥
    model_cache.commit()

    print(f"âœ… ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ì™„ë£Œ: {downloaded_path}")
    return downloaded_path


# ============================================================================
# 5. ë¹„ë””ì˜¤ ìƒì„± í•¨ìˆ˜ (í•µì‹¬ ê¸°ëŠ¥)
# ============================================================================
@app.function(
    image=image,
    volumes={MODEL_DIR: model_cache},
    secrets=[modal.Secret.from_name("huggingface-secret")],
    gpu="A10G",  # LTX-VideoëŠ” GPU í•„ìš” (A10GëŠ” ë¹„ìš© íš¨ìœ¨ì )
    timeout=600,  # 10ë¶„ (ë¹„ë””ì˜¤ ìƒì„±)
    memory=16384,  # 16GB RAM
)
def generate_video(
    image_url: str,
    prompt: str,
    duration: float = 8.0,
    fps: int = 24,
    seed: int = 42,
) -> bytes:
    """
    ì´ë¯¸ì§€ í•œ ì¥ì„ ë°›ì•„ì„œ 8ì´ˆì§œë¦¬ AI ë¹„ë””ì˜¤ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.

    Args:
        image_url: ì…ë ¥ ì´ë¯¸ì§€ URL (ìŠ¤í† ë¦¬ë³´ë“œ ì´ë¯¸ì§€)
        prompt: ë¹„ë””ì˜¤ ìƒì„± í”„ë¡¬í”„íŠ¸ (í‘œì •, ë™ì‘, ë°°ê²½ ì›€ì§ì„ ë“±)
        duration: ë¹„ë””ì˜¤ ê¸¸ì´ (ì´ˆ) - ê¸°ë³¸ 8ì´ˆ
        fps: ì´ˆë‹¹ í”„ë ˆì„ ìˆ˜ - ê¸°ë³¸ 24fps
        seed: ëœë¤ ì‹œë“œ (ì¬í˜„ì„±)

    Returns:
        ìƒì„±ëœ ë¹„ë””ì˜¤ ë°”ì´íŠ¸ (MP4)
    """
    import torch
    from diffusers import LTXPipeline
    from PIL import Image
    import requests
    from io import BytesIO
    import tempfile
    import os

    print(f"ğŸ¬ ë¹„ë””ì˜¤ ìƒì„± ì‹œì‘")
    print(f"   ì´ë¯¸ì§€: {image_url}")
    print(f"   í”„ë¡¬í”„íŠ¸: {prompt}")
    print(f"   ê¸¸ì´: {duration}ì´ˆ, FPS: {fps}")

    # ëª¨ë¸ ê²½ë¡œ
    model_path = Path(MODEL_DIR) / MODEL_NAME.replace("/", "--")

    if not model_path.exists():
        raise FileNotFoundError(
            f"ëª¨ë¸ì´ ì—†ìŠµë‹ˆë‹¤. download_model()ì„ ë¨¼ì € ì‹¤í–‰í•˜ì„¸ìš”: {model_path}"
        )

    # 1. ì…ë ¥ ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ
    print("ğŸ“¥ ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ ì¤‘...")
    response = requests.get(image_url)
    response.raise_for_status()
    input_image = Image.open(BytesIO(response.content)).convert("RGB")

    # 2. íŒŒì´í”„ë¼ì¸ ë¡œë“œ
    print("ğŸ”§ íŒŒì´í”„ë¼ì¸ ë¡œë“œ ì¤‘...")
    pipe = LTXPipeline.from_pretrained(
        str(model_path),
        torch_dtype=torch.bfloat16,
    ).to("cuda")

    # ë©”ëª¨ë¦¬ ìµœì í™”
    pipe.enable_model_cpu_offload()

    # 3. ë¹„ë””ì˜¤ ìƒì„±
    print("ğŸ¥ ë¹„ë””ì˜¤ ìƒì„± ì¤‘...")

    # í”„ë ˆì„ ìˆ˜ ê³„ì‚°
    num_frames = int(duration * fps)

    with torch.inference_mode():
        output = pipe(
            prompt=prompt,
            image=input_image,
            num_frames=num_frames,
            guidance_scale=3.0,  # ë‚®ì€ ê°’ = ì´ë¯¸ì§€ì— ë” ì¶©ì‹¤
            num_inference_steps=30,  # ì†ë„ì™€ í’ˆì§ˆì˜ ê· í˜•
            generator=torch.Generator("cuda").manual_seed(seed),
        )

    # 4. ë¹„ë””ì˜¤ ì €ì¥ (ì„ì‹œ íŒŒì¼)
    print("ğŸ’¾ ë¹„ë””ì˜¤ ì €ì¥ ì¤‘...")
    frames = output.frames[0]  # List of PIL Images

    with tempfile.NamedTemporaryFile(suffix=".mp4", delete=False) as tmp:
        temp_path = tmp.name

    # PIL ì´ë¯¸ì§€ë“¤ì„ MP4ë¡œ ë³€í™˜
    from diffusers.utils import export_to_video
    export_to_video(frames, temp_path, fps=fps)

    # 5. ë°”ì´íŠ¸ë¡œ ì½ì–´ì„œ ë°˜í™˜
    with open(temp_path, "rb") as f:
        video_bytes = f.read()

    # ì„ì‹œ íŒŒì¼ ì‚­ì œ
    os.unlink(temp_path)

    print(f"âœ… ë¹„ë””ì˜¤ ìƒì„± ì™„ë£Œ! í¬ê¸°: {len(video_bytes) / 1024 / 1024:.2f}MB")

    return video_bytes


# ============================================================================
# 6. ì›¹ ì—”ë“œí¬ì¸íŠ¸ (í”„ë¡ íŠ¸ì—”ë“œì—ì„œ í˜¸ì¶œ)
# ============================================================================
@app.function(
    image=image,
)
@modal.web_endpoint(method="POST")
def generate_video_endpoint(item: dict) -> dict:
    """
    í”„ë¡ íŠ¸ì—”ë“œì—ì„œ í˜¸ì¶œí•  REST API ì—”ë“œí¬ì¸íŠ¸

    Request Body:
    {
        "image_url": "https://...",
        "prompt": "subtle facial expressions, gentle background movement",
        "duration": 8.0,
        "fps": 24,
        "seed": 42
    }

    Response:
    {
        "status": "success",
        "video_url": "https://...",  # Modalì—ì„œ ì œê³µí•˜ëŠ” ì„ì‹œ URL
        "size_mb": 12.5
    }
    """
    import base64

    # ë¹„ë””ì˜¤ ìƒì„± (ë³‘ë ¬ í˜¸ì¶œ ê°€ëŠ¥)
    video_bytes = generate_video.remote(
        image_url=item["image_url"],
        prompt=item.get("prompt", "natural movement, subtle expressions"),
        duration=item.get("duration", 8.0),
        fps=item.get("fps", 24),
        seed=item.get("seed", 42),
    )

    # Base64 ì¸ì½”ë”©í•˜ì—¬ ë°˜í™˜ (ë˜ëŠ” S3/Cloudflare R2ì— ì—…ë¡œë“œ)
    video_base64 = base64.b64encode(video_bytes).decode()

    return {
        "status": "success",
        "video_base64": video_base64,
        "size_mb": len(video_bytes) / 1024 / 1024,
    }


# ============================================================================
# 7. ë¡œì»¬ í…ŒìŠ¤íŠ¸ìš© (ì„ íƒì‚¬í•­)
# ============================================================================
@app.local_entrypoint()
def main():
    """
    ë¡œì»¬ì—ì„œ í…ŒìŠ¤íŠ¸í•  ë•Œ ì‚¬ìš©
    í„°ë¯¸ë„ì—ì„œ: modal run modal-server/main.py
    """
    print("ğŸš€ LTX-Video ì„œë¹„ìŠ¤ í…ŒìŠ¤íŠ¸")
    print("1. ëª¨ë¸ ë‹¤ìš´ë¡œë“œ...")
    download_model.remote()
    print("âœ… ì™„ë£Œ!")
