ν•µμ‹¬ μ§€ν‘ (North Star)
- **μƒμ„± λΉ„μ©:** 8μ΄ μμƒ κΈ°μ¤€ 54μ› (Aggressive Quality Mode, ν™μ¨ 1,450μ›/$)
- **ν’μ§ μ°μ„ :** ν‘μ • & μ›€μ§μ„ ν•΄κ²° μµμ°μ„  (λΉ„μ© 2λ°° ν¬μ)

ν‘μ—… κ°€μ΄λ“ (Communication Rules)
- **μ„ μ μ  μ§λ¬Έ:** μ”κµ¬μ‚¬ν•­μ΄ λ¨νΈν•κ±°λ‚ λΉ„μ©/ν’μ§ νΈλ μ΄λ“μ¤ν”„κ°€ λ°μƒν•  κ²½μ° μ¦‰μ‹ μ§λ¬Έν•  κ²ƒ.
- **μµμ  μ μ•:** λ” μ €λ ΄ν•κ±°λ‚ ν¨μ¨μ μΈ λ°©μ‹μ΄ μλ‹¤λ©΄ μ‘μ—… μ „ λ€ν‘λ‹κ» λ¨Όμ € μ μ•ν•  κ²ƒ.
- **ν† ν° ν¨μ¨:** ν•­μƒ μµκ³ λ΅ ν¨μ¨μ μΌλ΅ νƒμƒ‰ν•  κ²ƒ. λ¶ν•„μ”ν• μ„μ μ„ μ§€μ–‘ν•κ³  ν•µμ‹¬ μ½”λ“μ™€ μ •λ³΄ μ„μ£Όλ΅ μ‘λ‹µν•μ—¬ ν† ν° μ‚¬μ©λ‰μ„ μµμ†ν™”ν•  κ²ƒ.
- ν•­μƒ cloud flareμ— μλ™λ°°ν¬ν•κΈ°

## β™οΈ Current Configuration (Aggressive Quality Mode)
- **Model:** LTX-2 Distilled + LoRA Rank 175 FP8 (1.79 GB)
- **Steps:** 20 (2λ°° μ¦κ°€, ν’μ§ μ°μ„ )
- **Guidance Scale:** 3.0 (ν”„λ΅¬ν”„νΈ κ°•ν™”)
- **Image Conditioning:** 0.85 (μ›€μ§μ„ μμ λ„)
- **Prompt:** "Cinematic motion, natural character movement, high dynamic range, subtle motion"
- **Cost:** ~β‚©54 per 8μ΄ video (84μ΄ μƒμ„± μ‹κ°„)

## π“¦ Repository & Backup
- **Main Repo:** `https://github.com/Breaduck/google-youtubeproject`
- **Modal API:** `https://hiyoonsh1--ltx-video-service-distilled-1080p-web-app.modal.run`
- **Cloudflare Pages:** `https://google-youtubeproject.pages.dev`
- **Sync Rule:** μ μλ―Έν• μ½”λ“ μμ •μ΄λ‚ μµμ ν™” μ‘μ—…μ΄ λλ‚λ©΄, μ‘μ—… λ‚΄μ—­μ„ μ”μ•½ν•μ—¬ μ„ λ ν¬μ§€ν† λ¦¬λ΅ λ°λ“μ‹ `git push` ν•  κ²ƒ.
- **Auto Deploy:** GitHub push β†’ Cloudflare Pages μλ™ λ°°ν¬ (1-2λ¶„)
- **Modal Deploy ν•„μ:** `modal-server/main.py` μμ • μ‹ git pushμ™€ λ™μ‹μ— λ°λ“μ‹ `python -m modal deploy modal-server/main.py` μ‹¤ν–‰ν•  κ²ƒ. (deploy.ps1 μ‚¬μ©: `powershell -ExecutionPolicy Bypass -File modal-server/deploy.ps1`)
- **Structure:** λ΅μ»¬ `video-saas` ν΄λ”μ μ‘μ—…λ¬Όμ„ λ ν¬μ§€ν† λ¦¬ κµ¬μ΅°μ— λ§μ¶° μΌκ΄€μ„± μκ² κ΄€λ¦¬ν•  κ²ƒ.

## πΏ ν„μ¬ μ‘μ—… λΈλμΉ
- **Active Branch:** `exp/official-sdk` β†’ μ‘μ—… νμΌ: `modal-server/main_official.py`
- **main λΈλμΉ νμΌ:** `modal-server/main.py` (λ³„λ„)

## π“ LTX-2 κ³µμ‹ SDK λ νΌλ°μ¤ (https://github.com/Lightricks/LTX-2)

### ν¨ν‚¤μ§€ κµ¬μ΅°
- `ltx-core`: λ¨λΈ κµ¬ν„ + μ¶”λ΅  μ ν‹Έ
- `ltx-pipelines`: κ³ μμ¤€ νμ΄ν”„λΌμΈ
- `ltx-trainer`: LoRA νμΈνλ‹

### νμ΄ν”„λΌμΈ μ„ νƒ
| νμ΄ν”„λΌμΈ | μ©λ„ |
|-----------|------|
| `TI2VidTwoStagesPipeline` | μµκ³  ν’μ§ (κ¶μ¥) |
| `DistilledPipeline` | μµκ³  μ†λ„ (8+4 steps) |
| `TI2VidOneStagePipeline` | λ‹¨μΌ ν¨μ¤ |
| `ICLoraPipeline` | Video-to-video |
| `KeyframeInterpolationPipeline` | ν‚¤ν”„λ μ„ λ³΄κ°„ |

### TI2VidTwoStagesPipeline μƒμ„±μ
```python
TI2VidTwoStagesPipeline(
    checkpoint_path: str,
    distilled_lora: list[LoraPathStrengthAndSDOps],  # strength 0.6 κ¶μ¥
    spatial_upsampler_path: str,
    gemma_root: str,
    loras: list[LoraPathStrengthAndSDOps],
    device: str = auto,
    quantization: QuantizationPolicy | None = None,
)
```

### TI2VidTwoStagesPipeline __call__
```python
pipeline(
    prompt: str,
    negative_prompt: str,
    seed: int,
    height: int, width: int,
    num_frames: int,
    frame_rate: float,
    num_inference_steps: int,
    video_guider_params: MultiModalGuiderParams,
    audio_guider_params: MultiModalGuiderParams,
    images: list[tuple[str, int, float]],  # (path, frame_idx, strength)
    tiling_config: TilingConfig | None = None,
    enhance_prompt: bool = False,
) -> tuple[Iterator[torch.Tensor], torch.Tensor]
```

### MultiModalGuiderParams κΈ°λ³Έκ°’
```python
MultiModalGuiderParams(
    cfg_scale=1.0,       # κ¶μ¥ λ²”μ„: 2.0~5.0
    stg_scale=0.0,       # κ¶μ¥ λ²”μ„: 0.5~1.5
    rescale_scale=0.0,
    modality_scale=1.0,
    stg_blocks=[29],
    skip_step=0,
)
```

### Sigma μ¤μΌ€μ¤„ (κ³µμ‹)
```python
DISTILLED_SIGMA_VALUES        = [1.0, 0.99375, 0.9875, 0.98125, 0.975, 0.909375, 0.725, 0.421875, 0.0]  # Stage1 (9κ°’)
STAGE_2_DISTILLED_SIGMA_VALUES = [0.909375, 0.725, 0.421875, 0.0]  # Stage2 (4κ°’)
```

### DistilledPipeline __call__
```python
pipeline(
    prompt, seed, height, width, num_frames, frame_rate,
    images: list[tuple[str, int, float]],
    tiling_config=None, enhance_prompt=False,
) -> tuple[Iterator[torch.Tensor], torch.Tensor]
# Stage1: height/2 x width/2 μƒμ„± β†’ Stage2: 2x μ—…μƒν” + μ •μ 
```

### LoRA λ΅λ“ ν¨ν„΄
```python
from ltx_core.loader import LTXV_LORA_COMFY_RENAMING_MAP, LoraPathStrengthAndSDOps
distilled_lora=[LoraPathStrengthAndSDOps("distilled_lora.safetensors", 0.6, LTXV_LORA_COMFY_RENAMING_MAP)]
```

### dtype / λ©”λ¨λ¦¬
- κΈ°λ³Έ dtype: `torch.bfloat16`
- FP8: `QuantizationPolicy.fp8_cast()` β†’ VRAM μ•½ 50% μ μ•½
- `PYTORCH_ALLOC_CONF=expandable_segments:True` ν•„μ

AI Self-Reflection & Auto-Fix Protocol
Pre-Deployment Sanity Check: λ¨λ“  μ½”λ“ μμ • ν›„ λ°°ν¬(Push) μ „, λ‹¤μ ν•­λ©μ„ μ¤μ¤λ΅ μ‹λ®¬λ μ΄μ…ν•λ‹¤.
VRAM μ²΄ν¬: LTX-2 + LoRA(Rank 175) μ΅°ν•©μ΄ A10G(24GB)μ—μ„ OOMμ„ μΌμΌν‚¤μ§€ μ•λ”κ°€?
μΈμ½”λ”© κ²€μ¦: μλ„μ° ν™κ²½μ CP949 μ¶©λ κ°€λ¥μ„±μ΄ μλ”κ°€? (UTF-8 κ°•μ  μ μ© μ—¬λ¶€)
μμ΅΄μ„± μ²΄ν¬: Modal ν™κ²½ κµ¬μ¶•μ— ν•„μ”ν• λΌμ΄λΈλ¬λ¦¬κ°€ λ„λ½λμ§€ μ•μ•λ”κ°€?
Auto-Fix Execution: κ²€ν†  κ³Όμ •μ—μ„ μ¤λ¥ κ°€λ¥μ„±μ΄ λ°κ²¬λλ©΄, μ‚¬μ©μμ—κ² λ³΄κ³ ν•κΈ° μ „ μ„ μ μ μΌλ΅ μ½”λ“λ¥Ό μμ •ν•μ—¬ 'μ •μƒ μ‘λ™' μƒνƒλ¥Ό λ§λ“  λ’¤ λ°°ν¬ν•λ‹¤.
Reflection Log: λ°°ν¬ μ‹, "μ¤μ¤λ΅ λ°κ²¬ν• μ μ¬μ  μ¤λ¥ λ° μ΄λ¥Ό ν•΄κ²°ν•κΈ° μ„ν•΄ μμ •ν• λ‚΄μ—­"μ„ μ§§κ³  λ…ν™•ν•κ² μ”μ•½ λ³΄κ³ ν•λ‹¤.